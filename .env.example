# GremlinsAI Backend Environment Configuration
# Copy this file to .env and update with your actual values
# NEVER commit .env files to version control!

# ===== CORE APPLICATION SETTINGS =====
APP_NAME=GremlinsAI Backend
APP_VERSION=9.0.0
ENVIRONMENT=development
DEBUG=false
LOG_LEVEL=INFO

# ===== SECRETS MANAGEMENT =====
# Choose your secrets backend: environment|vault|aws_secrets|gcp_secrets|azure_keyvault
SECRETS_BACKEND=environment

# HashiCorp Vault (if using vault backend)
# VAULT_URL=http://localhost:8200
# VAULT_TOKEN=your-vault-token

# AWS Secrets Manager (if using aws_secrets backend)
# AWS_REGION=us-east-1

# Google Secret Manager (if using gcp_secrets backend)
# GOOGLE_CLOUD_PROJECT=your-project-id
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# Azure Key Vault (if using azure_keyvault backend)
# AZURE_KEY_VAULT_URL=https://your-vault.vault.azure.net/

# ===== DATABASE CONFIGURATION =====
DATABASE_URL=sqlite:///./data/gremlinsai.db
# For PostgreSQL: postgresql+asyncpg://user:password@localhost:5432/gremlinsai
DATABASE_POOL_SIZE=10
DATABASE_MAX_OVERFLOW=20

# ===== SECURITY SETTINGS =====
# Generate a secure secret key: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=your-secret-key-change-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# ===== OAUTH2 CONFIGURATION =====
# Google OAuth
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret
OAUTH_REDIRECT_URL=http://localhost:8000/api/v1/oauth/google/callback

# Microsoft Azure OAuth
AZURE_CLIENT_ID=your-azure-client-id
AZURE_CLIENT_SECRET=your-azure-client-secret
AZURE_TENANT_ID=your-azure-tenant-id

# ===== LLM PROVIDER CONFIGURATION =====
# OpenAI
OPENAI_API_KEY=sk-your-openai-api-key

# Anthropic
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key

# Hugging Face
HUGGINGFACE_API_KEY=hf_your-huggingface-token

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# LLM Settings
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2048
LLM_TIMEOUT=60

# Hugging Face Local Models
USE_HUGGINGFACE=false
HF_MODEL=microsoft/DialoGPT-medium

# LlamaCpp Configuration
LLAMACPP_MODEL_PATH=./models/llama-2-7b-chat.gguf

# ===== VECTOR DATABASE CONFIGURATION =====
# Weaviate
WEAVIATE_URL=http://localhost:8080
WEAVIATE_API_KEY=your-weaviate-api-key
WEAVIATE_TIMEOUT=30

# Qdrant (legacy support)
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=gremlinsai_collection
QDRANT_API_KEY=your-qdrant-api-key

# ===== CACHE AND MESSAGE BROKER =====
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=your-redis-password
REDIS_TIMEOUT=5

# Celery Configuration
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# ===== OBJECT STORAGE =====
# MinIO/S3 Configuration
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=your-minio-access-key
MINIO_SECRET_KEY=your-minio-secret-key
MINIO_BUCKET=gremlinsai
MINIO_SECURE=false

# ===== MESSAGE STREAMING =====
KAFKA_BROKER_URLS=localhost:9092
KAFKA_USERNAME=your-kafka-username
KAFKA_PASSWORD=your-kafka-password

# ===== EMBEDDING AND SEARCH =====
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# ===== MULTIMODAL PROCESSING =====
MULTIMODAL_STORAGE_PATH=./data/multimodal
ENABLE_MULTIMODAL_PROCESSING=true
MAX_FILE_SIZE_MB=100

# ===== API CONFIGURATION =====
API_V1_PREFIX=/api/v1
API_RATE_LIMIT=100
API_TIMEOUT=30

# CORS Configuration (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8000,http://127.0.0.1:3000,http://127.0.0.1:8000

# ===== MONITORING AND OBSERVABILITY =====
ENABLE_METRICS=true
METRICS_PORT=8001
ENABLE_TRACING=false
JAEGER_ENDPOINT=http://localhost:14268/api/traces

# Health Check Configuration
HEALTH_CHECK_INTERVAL=30

# ===== DEVELOPMENT AND TESTING =====
TESTING=false
MOCK_EXTERNAL_SERVICES=false
