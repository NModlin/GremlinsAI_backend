{
  "dashboard": {
    "id": null,
    "title": "GremlinsAI Backend - AI Metrics Dashboard",
    "tags": ["gremlinsai", "ai", "monitoring", "production"],
    "style": "dark",
    "timezone": "browser",
    "refresh": "30s",
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "panels": [
      {
        "id": 1,
        "title": "API Request Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(gremlinsai_api_requests_total[5m]))",
            "legendFormat": "Requests/sec",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 10},
                {"color": "red", "value": 50}
              ]
            },
            "unit": "reqps"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "API Error Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(gremlinsai_api_errors_total[5m]))",
            "legendFormat": "Errors/sec",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 0.1},
                {"color": "red", "value": 1}
              ]
            },
            "unit": "reqps"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 6, "y": 0}
      },
      {
        "id": 3,
        "title": "API Response Time (95th percentile)",
        "type": "stat",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(gremlinsai_api_request_duration_seconds_bucket[5m])) by (le))",
            "legendFormat": "95th percentile",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 2},
                {"color": "red", "value": 5}
              ]
            },
            "unit": "s"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 12, "y": 0}
      },
      {
        "id": 4,
        "title": "Active Conversations",
        "type": "stat",
        "targets": [
          {
            "expr": "gremlinsai_active_conversations",
            "legendFormat": "Active",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 100},
                {"color": "red", "value": 500}
              ]
            },
            "unit": "short"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 18, "y": 0}
      },
      {
        "id": 5,
        "title": "API Requests by Endpoint",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(gremlinsai_api_requests_total[5m])) by (endpoint)",
            "legendFormat": "{{endpoint}}",
            "refId": "A"
          }
        ],
        "yAxes": [
          {
            "label": "Requests/sec",
            "min": 0
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
      },
      {
        "id": 6,
        "title": "API Response Time by Endpoint",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(gremlinsai_api_request_duration_seconds_bucket[5m])) by (le, endpoint))",
            "legendFormat": "{{endpoint}} (95th)",
            "refId": "A"
          },
          {
            "expr": "histogram_quantile(0.50, sum(rate(gremlinsai_api_request_duration_seconds_bucket[5m])) by (le, endpoint))",
            "legendFormat": "{{endpoint}} (50th)",
            "refId": "B"
          }
        ],
        "yAxes": [
          {
            "label": "Response Time (s)",
            "min": 0
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
      },
      {
        "id": 7,
        "title": "LLM Response Time",
        "type": "stat",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(gremlinsai_llm_response_duration_seconds_bucket[5m])) by (le))",
            "legendFormat": "95th percentile",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 10},
                {"color": "red", "value": 30}
              ]
            },
            "unit": "s"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 0, "y": 16}
      },
      {
        "id": 8,
        "title": "LLM Request Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(gremlinsai_llm_requests_total[5m]))",
            "legendFormat": "Requests/sec",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 5},
                {"color": "red", "value": 20}
              ]
            },
            "unit": "reqps"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 6, "y": 16}
      },
      {
        "id": 9,
        "title": "LLM Error Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(gremlinsai_llm_errors_total[5m]))",
            "legendFormat": "Errors/sec",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 0.05},
                {"color": "red", "value": 0.2}
              ]
            },
            "unit": "reqps"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 12, "y": 16}
      },
      {
        "id": 10,
        "title": "LLM Fallback Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(gremlinsai_llm_fallback_total[5m]))",
            "legendFormat": "Fallbacks/sec",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 0.01},
                {"color": "red", "value": 0.1}
              ]
            },
            "unit": "reqps"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 18, "y": 16}
      },
      {
        "id": 11,
        "title": "LLM Response Time by Provider",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(gremlinsai_llm_response_duration_seconds_bucket[5m])) by (le, provider))",
            "legendFormat": "{{provider}} (95th)",
            "refId": "A"
          },
          {
            "expr": "histogram_quantile(0.50, sum(rate(gremlinsai_llm_response_duration_seconds_bucket[5m])) by (le, provider))",
            "legendFormat": "{{provider}} (50th)",
            "refId": "B"
          }
        ],
        "yAxes": [
          {
            "label": "Response Time (s)",
            "min": 0
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24}
      },
      {
        "id": 12,
        "title": "LLM Token Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(gremlinsai_llm_tokens_total[5m])) by (provider)",
            "legendFormat": "{{provider}}",
            "refId": "A"
          }
        ],
        "yAxes": [
          {
            "label": "Tokens/sec",
            "min": 0
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24}
      },
      {
        "id": 13,
        "title": "Agent Tool Success Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(gremlinsai_agent_tool_usage_total{status=\"success\"}[5m])) / sum(rate(gremlinsai_agent_tool_usage_total[5m]))",
            "legendFormat": "Success Rate",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "red", "value": null},
                {"color": "yellow", "value": 0.8},
                {"color": "green", "value": 0.95}
              ]
            },
            "unit": "percentunit",
            "min": 0,
            "max": 1
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 0, "y": 32}
      },
      {
        "id": 14,
        "title": "Agent Reasoning Steps",
        "type": "stat",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(gremlinsai_agent_reasoning_steps_bucket[5m])) by (le))",
            "legendFormat": "95th percentile",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 5},
                {"color": "red", "value": 10}
              ]
            },
            "unit": "short"
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 6, "y": 32}
      },
      {
        "id": 15,
        "title": "RAG Relevance Score",
        "type": "stat",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, sum(rate(gremlinsai_rag_relevance_score_bucket[5m])) by (le))",
            "legendFormat": "Median Score",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "red", "value": null},
                {"color": "yellow", "value": 0.3},
                {"color": "green", "value": 0.7}
              ]
            },
            "unit": "short",
            "min": 0,
            "max": 1
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 12, "y": 32}
      },
      {
        "id": 16,
        "title": "RAG Cache Hit Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(gremlinsai_rag_cache_total{cache_status=\"hit\"}[5m])) / sum(rate(gremlinsai_rag_cache_total[5m]))",
            "legendFormat": "Hit Rate",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "red", "value": null},
                {"color": "yellow", "value": 0.5},
                {"color": "green", "value": 0.8}
              ]
            },
            "unit": "percentunit",
            "min": 0,
            "max": 1
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 18, "y": 32}
      },
      {
        "id": 17,
        "title": "Tool Usage by Type",
        "type": "piechart",
        "targets": [
          {
            "expr": "sum(rate(gremlinsai_agent_tool_usage_total[5m])) by (tool_name)",
            "legendFormat": "{{tool_name}}",
            "refId": "A"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 40}
      },
      {
        "id": 18,
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "gremlinsai_memory_usage_bytes",
            "legendFormat": "{{component}}",
            "refId": "A"
          }
        ],
        "yAxes": [
          {
            "label": "Memory (bytes)",
            "min": 0
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 40}
      }
    ],
    "templating": {
      "list": [
        {
          "name": "interval",
          "type": "interval",
          "query": "1m,5m,10m,30m,1h",
          "current": {
            "text": "5m",
            "value": "5m"
          }
        }
      ]
    },
    "annotations": {
      "list": [
        {
          "name": "Deployments",
          "datasource": "Prometheus",
          "enable": true,
          "expr": "changes(gremlinsai_app_info[1h])",
          "iconColor": "rgba(0, 211, 255, 1)",
          "titleFormat": "Deployment"
        }
      ]
    },
    "schemaVersion": 30,
    "version": 1
  }
}
