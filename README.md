# gremlinsAI Backend

A sophisticated, headless, multi-modal AI system built with FastAPI, CrewAI, and Qdrant, featuring specialized multi-agent capabilities, semantic search, and RAG (Retrieval-Augmented Generation) that can reason across text, collaborate on complex tasks, and maintain conversation context through persistent chat history and document knowledge.

## ğŸš€ Features

### Phase 1: Core Agent Engine
- **LangGraph-based Agent**: Advanced agent workflow with tool integration
- **DuckDuckGo Search**: Web search capabilities for real-time information
- **FastAPI Framework**: Modern, fast API with automatic documentation
- **Tool Integration**: Extensible architecture for adding new tools

### Phase 2: Robust API Layer
- **Chat History**: Persistent conversation storage with SQLite database
- **Context Awareness**: Multi-turn conversations with memory
- **CRUD Operations**: Complete conversation and message management
- **Database Migrations**: Alembic-powered schema management

### Phase 3: Advanced Multi-Agent Architecture
- **CrewAI Integration**: Sophisticated multi-agent orchestration
- **Specialized Agent Roles**: Researcher, Analyst, Writer, Coordinator
- **Complex Workflows**: Multi-step reasoning and task coordination
- **Agent Memory System**: Persistent context sharing between agents
- **Enhanced API Endpoints**: New multi-agent workflow capabilities
- **100% Backward Compatibility**: All existing functionality preserved

### Phase 4: Data Infrastructure Overhaul âœ… COMPLETE
- **Qdrant Vector Store**: High-performance semantic search capabilities
- **Document Management**: Intelligent chunking and storage system
- **RAG System**: Retrieval-Augmented Generation for enhanced responses
- **Semantic Search**: Vector similarity search with metadata filtering
- **Document APIs**: Complete CRUD operations for knowledge management
- **Analytics & Monitoring**: Search analytics and system health monitoring

## ğŸ“‹ Requirements

- Python 3.11+
- SQLite (included with Python)
- Internet connection (for DuckDuckGo search)

## ğŸ› ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd GremlinsAI_backend
   ```

2. **Create virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

5. **Initialize database**
   ```bash
   alembic upgrade head
   ```

## ğŸ¯ Production Status

**âœ… PRODUCTION READY** - All phases implemented and validated

The gremlinsAI system has completed comprehensive end-to-end testing with **100% test pass rate** (25/25 tests). The system is ready for production deployment with all four phases working harmoniously:

- **Phase 1**: Core agent engine with LangGraph âœ…
- **Phase 2**: Persistent conversation management âœ…
- **Phase 3**: Multi-agent architecture with CrewAI âœ…
- **Phase 4**: Document management and RAG capabilities âœ…

See [PRODUCTION_VALIDATION_REPORT.md](PRODUCTION_VALIDATION_REPORT.md) for detailed validation results.

## ğŸš€ Quick Start

### Start the Server
```bash
# Using the provided script
./start.sh

# Or directly with uvicorn
uvicorn app.main:app --host 127.0.0.1 --port 8000 --reload
```

### Access API Documentation
- **Interactive Docs**: http://127.0.0.1:8000/docs
- **ReDoc**: http://127.0.0.1:8000/redoc

## ğŸ“š API Usage

### Simple Agent Query (Phase 1)
```bash
curl -X POST "http://127.0.0.1:8000/api/v1/agent/invoke" \
  -H "Content-Type: application/json" \
  -d '{"input": "What is artificial intelligence?"}'
```

### Context-Aware Chat (Phase 2)
```bash
# Start a conversation
curl -X POST "http://127.0.0.1:8000/api/v1/agent/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "What is machine learning?",
    "save_conversation": true
  }'

# Continue the conversation with context
curl -X POST "http://127.0.0.1:8000/api/v1/agent/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Can you explain that in simpler terms?",
    "conversation_id": "your-conversation-id",
    "save_conversation": true
  }'
```

### Document Management & RAG (Phase 4) âœ… COMPLETE
```bash
# Create a document with automatic chunking
curl -X POST "http://127.0.0.1:8000/api/v1/documents/" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "AI Research Paper",
    "content": "Artificial intelligence research shows...",
    "tags": ["ai", "research"],
    "chunk_size": 1000
  }'

# Semantic search across documents
curl -X POST "http://127.0.0.1:8000/api/v1/documents/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "machine learning algorithms",
    "limit": 5,
    "search_type": "chunks"
  }'

# RAG query with document context
curl -X POST "http://127.0.0.1:8000/api/v1/documents/rag" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Explain neural networks based on available documents",
    "use_multi_agent": true,
    "search_limit": 3
  }'
```

### Multi-Agent Workflows (Phase 3)
```bash
# Execute multi-agent workflow
curl -X POST "http://127.0.0.1:8000/api/v1/multi-agent/workflow" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Analyze the impact of renewable energy on the economy",
    "workflow_type": "research_analyze_write",
    "save_conversation": true
  }'

# Get agent capabilities
curl "http://127.0.0.1:8000/api/v1/multi-agent/capabilities"

# Enhanced chat with multi-agent support
curl -X POST "http://127.0.0.1:8000/api/v1/agent/chat?use_multi_agent=true" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Explain quantum computing in simple terms",
    "save_conversation": true
  }'
```

### Chat History Management
```bash
# List conversations
curl "http://127.0.0.1:8000/api/v1/history/conversations"

# Get conversation details
curl "http://127.0.0.1:8000/api/v1/history/conversations/{conversation_id}"

# Get conversation messages
curl "http://127.0.0.1:8000/api/v1/history/conversations/{conversation_id}/messages"

# Get conversation summary with agent interactions
curl "http://127.0.0.1:8000/api/v1/multi-agent/conversations/{conversation_id}/summary"
```

## ğŸ—ï¸ Architecture

```
gremlinsAI_backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/v1/
â”‚   â”‚   â”œâ”€â”€ endpoints/          # API route handlers
â”‚   â”‚   â””â”€â”€ schemas/            # Pydantic models
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ agent.py           # LangGraph agent implementation
â”‚   â”‚   â””â”€â”€ tools.py           # Agent tools (search, etc.)
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ database.py        # Database configuration
â”‚   â”‚   â””â”€â”€ models.py          # SQLAlchemy models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ chat_history.py    # Business logic layer
â”‚   â””â”€â”€ main.py                # FastAPI application
â”œâ”€â”€ alembic/                   # Database migrations
â”œâ”€â”€ data/                      # SQLite database storage
â””â”€â”€ requirements.txt           # Python dependencies
```

## ğŸ”§ Configuration

### Environment Variables (.env)
```bash
# Core Application Settings
LOG_LEVEL="INFO"
DATABASE_URL="sqlite:///./data/gremlinsai.db"

# Future Phase Configurations
OLLAMA_BASE_URL="http://localhost:11434"
QDRANT_HOST="localhost"
QDRANT_PORT="6333"
REDIS_URL="redis://localhost:6379"
```

## ğŸ—„ï¸ Database Management

### Run Migrations
```bash
# Upgrade to latest schema
alembic upgrade head

# Create new migration
alembic revision --autogenerate -m "Description"

# Check current version
alembic current
```

## ğŸ”Œ API Endpoints

### Agent Endpoints
- `POST /api/v1/agent/invoke` - Simple agent invocation
- `POST /api/v1/agent/chat` - Context-aware chat with history

### Chat History Endpoints
- `POST /api/v1/history/conversations` - Create conversation
- `GET /api/v1/history/conversations` - List conversations
- `GET /api/v1/history/conversations/{id}` - Get conversation
- `PUT /api/v1/history/conversations/{id}` - Update conversation
- `DELETE /api/v1/history/conversations/{id}` - Delete conversation
- `POST /api/v1/history/messages` - Add message
- `GET /api/v1/history/conversations/{id}/messages` - Get messages
- `GET /api/v1/history/conversations/{id}/context` - Get AI context

## ğŸ§ª Development

### Code Quality
- Follow PEP 8 style guidelines
- Use type hints throughout the codebase
- Maintain comprehensive docstrings

### Adding New Tools
1. Implement tool function in `app/core/tools.py`
2. Add tool to the agent's tool list in `app/core/agent.py`
3. Update API documentation

### Database Changes
1. Modify models in `app/database/models.py`
2. Generate migration: `alembic revision --autogenerate -m "Description"`
3. Apply migration: `alembic upgrade head`

## ğŸš¦ Deployment

### Production Considerations
- Use a production WSGI server (e.g., Gunicorn)
- Configure proper logging levels
- Set up database backups
- Use environment-specific configuration
- Enable HTTPS in production

### Docker Deployment (Future)
```dockerfile
# Dockerfile example for future use
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ”® Future Phases

- **Phase 3**: Advanced Agent Architecture with CrewAI
- **Phase 4**: Data Infrastructure with Vector Stores
- **Phase 5**: Agent Orchestration & Scalability
- **Phase 6**: API Modernization with GraphQL
- **Phase 7**: Multi-Modal Revolution (Audio/Video)
- **Phase 8**: Developer Enablement & Documentation

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“ Support

For questions and support, please open an issue in the repository or contact the development team.
